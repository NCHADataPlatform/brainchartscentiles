---
title: "BrainChart calibration tutorial"
format: html
---

```{r, echo=FALSE}
knitr::read_chunk("calibration_example_hbn.R")
```

# Introduction

The code in this repository extends the original BrainChart codebase, and
therefore can't be assembled into a standard R package without restructuring 
that code.

The functionality in this repository is accessed via the following code snippet.

```{r Setup, message = FALSE, warning = FALSE}
source('calibrate_braincharts_centiles.R')
```
```{r Pacakges, echo=FALSE}
library('pracma')
```

__IMPORTANT NOTE__ A full path to `calibrate_braincharts_centiles.R` must be provided 
if your code is outside this repository. e.g.

```{r, eval=FALSE}
BrainChartFolder <- dirname(normalizePath("~/Projects/brainchartscentiles/calibrate_braincharts_centiles.R"))
source(file.path(BrainChartFolder, 'calibrate_braincharts_centiles.R'))
```



Using the calibration functions requires the following steps:

1. Loading brain IDPs
1. Attaching demographic and site data
1. Renaming columns

This tutorial illustrates calibration using a combination of data from the healthy
brain network and synthetic data. The code can be used as a template to
calibrate your own data.

Note that some output from the code snippets has been supressed to make cleaner
documentation. The code used to create this tutorial is available in the file
`calibration_example_hbn.R`.

# Loading FreeSurfer and demographic data

## Helper function and loading FreeSurfer data

First load the study FreeSurfer data. These tables are collated from the individual 
study statistics using the FreeSurfer `asegstats2table` and `aparcstats2table`
utilities, as illustrated in the bash script named `freesurfer_make_stats.sh`.

```{r LoadingStructuralData, message=FALSE}
asegDF <- read.csv(file.path('HBN', 'stats_aseg.csv'))
lhCortThicknessDF <- read.csv(file.path('HBN', 'stats_aparc_lh_thickness.csv'))
lhCortSurfaceAreaDF <- read.csv(file.path('HBN', 'stats_aparc_lh_area.csv'))
rhCortThicknessDF <- read.csv(file.path('HBN', 'stats_aparc_lh_thickness.csv'))
rhCortSurfaceAreaDF <- read.csv(file.path('HBN', 'stats_aparc_rh_area.csv'))
```

## Set up IDP columns

Next, we select columns of interest and combine and rename them as required by the
BrainChart calibration process. We then join the per-hemisphere surface-based
metrics to the volume metrics and optionally discard columns not required by 
calibration.

```{r MakeIDPColumns}
brainChartsDF <- select(asegDF, ID, 
                        CerebralWhiteMatterVol, 
                        SubCortGrayVol, CortexVol, 
                        EstimatedTotalIntraCranialVol, 
                        Left.Lateral.Ventricle, Right.Lateral.Ventricle, 
                        SupraTentorialVolNotVent, BrainSegVol.to.eTIV)
brainChartsDF <- mutate(brainChartsDF, 
                        Ventricles = Left.Lateral.Ventricle + 
                          Right.Lateral.Ventricle, BrainSegVol.to.eTIV)

brainChartsDF <- rename(brainChartsDF, 
                        WMV = CerebralWhiteMatterVol,
                        sGMV = SubCortGrayVol,
                        GMV = CortexVol,
                        etiv = EstimatedTotalIntraCranialVol,
                        TCV = SupraTentorialVolNotVent,
                        )
# join surface area measures
brainChartsDF <- left_join(brainChartsDF, 
                           select(lhCortSurfaceAreaDF, ID, 
                                  lh_WhiteSurfArea_area), by="ID")
brainChartsDF <- left_join(brainChartsDF, 
                           select(rhCortSurfaceAreaDF, ID, 
                                  rh_WhiteSurfArea_area), by="ID")
# join cortical thickness measures
brainChartsDF <- left_join(brainChartsDF, 
                           select(lhCortThicknessDF, ID, 
                                  lh_MeanThickness_thickness), by="ID")
brainChartsDF <- left_join(brainChartsDF, 
                           select(rhCortThicknessDF, ID, 
                                  rh_MeanThickness_thickness), by="ID")

brainChartsDF <- mutate(brainChartsDF, 
                        SA = lh_WhiteSurfArea_area + rh_WhiteSurfArea_area)
brainChartsDF <- mutate(brainChartsDF, 
                        CT = ((lh_MeanThickness_thickness * 
                                 lh_WhiteSurfArea_area) + 
                                (rh_MeanThickness_thickness * 
                                   rh_WhiteSurfArea_area))/SA,
                        )

brainChartsDF <- select(brainChartsDF, -Right.Lateral.Ventricle, 
                        -Left.Lateral.Ventricle, 
                        -ends_with("area"), -ends_with("thickness"))

```

## Set up other required columns

Here, we make the columns `fs_version` (the version of FreeSurfer used for processing), `run` (an identifier for the acquisition session), `participant` (the subject IDs), `country` (acquisition country, *unused*).

```{r MakeOtherColumns}

brainChartsDF <- mutate(brainChartsDF, 
                        fs_version = 'Custom_T1T2',
                        run = 1,
                        participant = ID,
                        country = 'Australia',
                        )
```

## Set up the study column

The `study` column contains the identifier for the sample each set of measurements belongs to. It can be an arbitrary string, and all measurements belonging to the same sample must have the same value. It cannot be one of the studies in the Braincharts' training set, which are as follows: 3R-BRAIN, ABCD, abide1, abide2, ADHD200, ADNI, AIBL, AOBA, AOMIC_ID1000, AOMIC_PIOP1, AOMIC_PIOP2, ARWIBO, BabyConnectome, BGSP, BHRCS, BSNIP, Calgary, CALM, CamCAN, CAMFT, Cornell_C1, Cornell_C2, cVEDA, devCCNP, dHCP, DLBS, EDSD, EMBARC, FemaleASD, FinnBrain, GUSTO, HABS, Harvard_Fetal1, HBN, HCP, HCP_lifespanA, HCP_lifespanD, IBIS, ICBM, IMAGEN, IMAP, IXI, LA5c, MCIC, Narratives, NHGRI, NIH, NIHPD, NSPN, NTB_Yale, OASIS3, Oulu, PCDC, PING, PNC, POND, PREVENTAD,  RDB, SALD, SLIM, UCSD, UKB, VETSA, WAYNE.

In this example, we set the study column later via the demographic data.

## Set up the diagnosis/group column

The `dx` column assigns participants to control `CN` (for calibration) or other `notCN` (not for calibration). Here, all subjects are controls, so we set it as follows:

```{r MakeDXColumn}
brainChartsDF <- mutate(brainChartsDF, 
                        dx = "CN"
                        )
```

Derived values, such as centiles, are estimated for non-controls, but these measurements are not used for calibration.

## Prepare demographic information

Preparing the demographic information is similar. In the HBN dataset the
demographic tables are provided on a per-study basis, so we load them individually,
create a study column, combine into a single table, create an `age_days` column
and rename the `Sex` column and set up the factor levels. We set the `study` column according to the acquisition site (CBIC, CUNY, SI, HBNRU).

```{r LoadDemo}
demoCBIC <- read_csv(file.path('HBN', 'participants-CBIC.csv'), 
                     show_col_types = FALSE)
demoCUNY <- read_csv(file.path('HBN', 'participants-CUNY.csv'), 
                     show_col_types = FALSE)
demoSI <- read_csv(file.path('HBN', 'participants-SI.csv'), 
                   show_col_types = FALSE)
demoRU <- read_csv(file.path('HBN', 'participants-RU.csv'), 
                   show_col_types = FALSE)

demoCBIC <- mutate(demoCBIC, study = 'HBNCBIC')
demoCUNY <- mutate(demoCUNY,study = 'HBNCUNY')
demoSI <- mutate(demoSI, study = 'HBNSI')
demoRU <- mutate(demoRU , study = 'HBNRU')

demoDF <- bind_rows(demoCBIC, demoCUNY, demoSI, demoRU)
demoDF <- mutate(demoDF, age_days = Age * 365.25)
demoDF <- rename(demoDF, sex = Sex)

demoDF <- mutate(demoDF, 
                 sex = factor(sex, labels = c("Male", "Female"), 
                                      levels = c(0, 1)))
```


## Combining IDP and demographic tables

Finally, we merge the demographic and IDP tables using the study ID as a key, and
exclude any incomplete records.

More complex studies may require merging by combinations of multiple columns,
such as ID and time point or site.

```{r JoinDemographics}
brainChartsDF <- left_join(brainChartsDF, 
                           select(demoDF, participant_id, sex, age_days, study), 
                           by=join_by(ID==participant_id))

brainChartsDF <- na.omit(brainChartsDF)

brainChartsDF <- mutate(brainChartsDF, study = factor(study, levels=c("HBNCBIC", "HBNCUNY", "HBNRU", "HBNSI")))
```

# Calibration

## Study overview

Perform a quick check of study numbers and breakdown by sex to ensure that
the data is correctly loaded

```{r StudyOverview}
count(brainChartsDF, study)
count(brainChartsDF, study, sex, sort = FALSE)

```

## Calibration, Phase 1
Phase 1 of calibration is the standard, cross sectional, version proposed
in the original BrainCharts paper. We show cortical thickness as the IDP of interest. 
We perform this on a per-study basis, since each study represents a single sample. We will only show one site (CBIC), since we only require one site to illustrate usage.

```{r CalibrationPhase1, warning=FALSE, echo=TRUE}
brainChartsDF <- data.frame(brainChartsDF)
brainChartsDF <- filter(brainChartsDF, study == "HBNCBIC")
row.names(brainChartsDF) <- brainChartsDF$participant
fullSampleCBICCalibration <- calibrateBrainCharts(brainChartsDF, phenotype = "CT")
```

The results data structure will be described, this is purely for reference. The dataframe *fullSampleCBICCalibration* is the output

- `fullSampleCBICCalibration$expanded`: The model parameters 
    - `fullSampleCBICCalibration$expanded$mu$ranef`: The $\mu$ site-effect estimates. The user-provided study name will be the estimated effect for the sample, in this example it is `fullSampleCBICCalibration$expanded$mu$ranef[['HBNCBIC']]`
    - `fullSampleCBICCalibration$expanded$sigma$ranef`: The $\mu$ site-effect estimates. The user-provided study name will be the estimated effect for the sample, in this example it is `fullSampleCBICCalibration$expanded$mu$ranef[['HBNCBIC']]`
- `fullSampleCBICCalibration$DATA.PRED`: The data with predicted values from the model *before* calibration
- `fullSampleCBICCalibration$DATA.PRED2`: The data with predicted values for parameters *after* calibration
    - `fullSampleCBICCalibration$DATA.PRED2$meanCT2transformed`: the transformed cortical thickness values
    - `fullSampleCBICCalibration$DATA.PRED2$mu.wre`: the estimated $\mu$ for each measurement
    - `fullSampleCBICCalibration$DATA.PRED2$sigma.wre`: the estimated $\sigma$ for each measurement
    - `fullSampleCBICCalibration$DATA.PRED2$PRED.l250.wre`: the estimated 0.25 centile for each measurement
    - `fullSampleCBICCalibration$DATA.PRED2$PRED.m500.wre`: the estimated 0.5 (median) centile for each measurement
    - `fullSampleCBICCalibration$DATA.PRED2$PRED.u750.wre`: the estimated 0.75 centile for each measurement

ggsave('freesurfer_example_hbn_CBIC.png')
## Calibration, Phase 2
Phase 2 of calibration is the "small" sample calibration. For this example, we have to simulate a "small" repeated-measures sample. To do this we create a synthetic, longitudinal follow up sample with slightly altered parameters. The code is presented here but wouldn't apply in a real-world exmaple

```{r CalibrationPhase2Setup, warning=FALSE}
brainChartsDF$mu.wre <- NA
brainChartsDF$sigma.wre <- NA
brainChartsDF$nu.wre <- NA

brainChartsDF[row.names(fullSampleCBICCalibration$DATA.PRED2), 'mu.wre'] <- fullSampleCBICCalibration$DATA.PRED2$mu.wre
brainChartsDF[row.names(fullSampleCBICCalibration$DATA.PRED2), 'sigma.wre'] <- fullSampleCBICCalibration$DATA.PRED2$sigma.wre
brainChartsDF[row.names(fullSampleCBICCalibration$DATA.PRED2), 'nu.wre'] <- fullSampleCBICCalibration$DATA.PRED2$nu.wre

brainChartsDF <- filter(brainChartsDF, study == "HBNCBIC")
# generate a new table with altered distribution parameters
brainChartsDFFake <- data.frame(brainChartsDF)

# add timepoint effects
muNudge <- 0.1
sigmaNudge <- 0.1
brainChartsDFFake$mu.wre <- brainChartsDF$mu.wre + muNudge
brainChartsDFFake$sigma.wre <- brainChartsDF$sigma.wre + sigmaNudge

# add a year to the ages and some randomness
brainChartsDFFake$age_days <- brainChartsDFFake$age_days + 365.25 + abs(rnorm(nrow(brainChartsDFFake), mean = 0, sd = 10))
# generate variables from altered distributions
brainChartsDFFake$CT <- rGGalt(nrow(brainChartsDFFake), exp(brainChartsDFFake$mu.wre), exp(brainChartsDFFake$sigma.wre), brainChartsDFFake$nu.wre) * 10000

# add "2" to the study name to make it a new sample
brainChartsDFFake$study <- paste0(brainChartsDFFake$study, "2")
```

Now, we select a random subsample of the CBIC study from the synthetic timepoint.

```{r CalibrationPhase2Select, warning=FALSE}
n <- 50
subFakeCBIC <- filter(brainChartsDFFake, study == "HBNCBIC2")
P <- randperm(1:nrow(subFakeCBIC))
subFakeCBIC <- subFakeCBIC[P[1:n],]
```

Here, `subFakeCBIC` would represent the "small" sample an investigator is wishing to calibrate. We calibrate this sample using the centile-informed repeated measures method, using the large site calibration output previously computed as follows:

```
subFakeCBICOutQuantile <- calibrateBrainChartsIDQuantilePenalty(subFakeCBIC, phenotype = "CT", largeSiteOutput = fullSampleCBICCalibration)
```


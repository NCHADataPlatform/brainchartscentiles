---
title: "BrainChart calibration - assessing accuracy of centile method"
format: html
---

```{r, echo=FALSE}
knitr::read_chunk("calibration_example_hbn_accuracy.R")
```

# Introduction

This tutorial demonstrates how to assess the accuracy of the proposed centile-informed calibration compared to the original Braincharts' method on small samples on the HBN dataset. 
The first thing to do is source the script that loads and performs the original calibration:

```{r Packages, message = FALSE, warning = FALSE, echo = FALSE}
```

# Calibration - Braincharts' calibration on the small sample

The normal calibration is now performed on the small sample using the original Braincharts' method:

```{r Calib1, message = FALSE, warning = FALSE}
```

# Calibration - Braincharts' calibration on the full fake sample

We now calibrate the entire fake sample. The computed parameters are used as ground truth for evaluation:

```{r Calib3, message = FALSE, warning = FALSE}
```

# Make plots for evaluation

The plot shows the estimated centiles of the site-corrected distributions from the full synthetic dataset, this is ground truth, and the estimated centiles. The closer the estimated centiles are to the ground truth ones, the more accurate the method is.

```{r MakePlots, message = FALSE, warning = FALSE}
```

